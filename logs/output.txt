#0 building with "default" instance using docker driver

#1 [internal] load build definition from python.dockerfile
#1 transferring dockerfile: 1.54kB 0.0s done
#1 DONE 0.0s

#2 [internal] load metadata for docker.io/library/python:3.12-slim
#2 DONE 0.1s

#3 [internal] load .dockerignore
#3 transferring context: 79B 0.1s done
#3 DONE 0.1s

#4 [ 1/17] FROM docker.io/library/python:3.12-slim@sha256:590cad70271b6c1795c6a11fb5c110efca593adbd0d4883cd19c36df6a56467b
#4 DONE 0.0s

#5 [internal] load build context
#5 transferring context: 9.87kB 1.0s done
#5 DONE 1.0s

#6 [ 9/17] COPY tests/ tests/
#6 CACHED

#7 [ 3/17] RUN apt-get update && apt-get install -y --no-install-recommends     build-essential     make     pandoc     default-jre-headless  && pip install --upgrade pip setuptools wheel build  && rm -rf /var/lib/apt/lists/*
#7 CACHED

#8 [ 6/17] RUN python -m spacy download en_core_web_sm
#8 CACHED

#9 [11/17] COPY datasets/ datasets/
#9 CACHED

#10 [10/17] COPY smoke/ smoke/
#10 CACHED

#11 [ 2/17] WORKDIR /pipeline
#11 CACHED

#12 [ 4/17] COPY deps/requirements.txt .
#12 CACHED

#13 [ 7/17] RUN python -m nltk.downloader punkt punkt_tab stopwords
#13 CACHED

#14 [ 5/17] RUN pip install --no-cache-dir -r requirements.txt
#14 CACHED

#15 [ 8/17] COPY src/ src/
#15 CACHED

#16 [12/17] COPY .env .env
#16 CACHED

#17 [13/17] COPY Makefile .
#17 DONE 0.1s

#18 [14/17] RUN make env-docker
#18 0.456 âœ“ Generated .env.docker
#18 DONE 0.5s

#19 [15/17] RUN mv .env.docker .env
#19 DONE 0.3s

#20 [16/17] COPY pyproject.toml pytest.ini conftest.py .
#20 DONE 0.1s

#21 [17/17] COPY logs/elapsed_time.csv logs/
#21 DONE 0.0s

#22 exporting to image
#22 exporting layers 0.1s done
#22 writing image sha256:f67bb181024c0e3c0b1e969bc2b86032fb27105918c0bd7998ed774fa89a9648 done
#22 naming to docker.io/library/dsci-cap-img-python-dev:latest done
#22 DONE 0.1s
44bdee9156b685a2461c0d8bf45cb15cdf264281b0151c9bbd2eeea302e6427a
Network 'capstone_default' already exists; continue...
Deleted old chunks...
 * Serving Flask app 'src.core.boss'
 * Debug mode: off
[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5054
 * Running on http://172.17.0.5:5054
[33mPress CTRL+C to quit[0m
[STATUS] Story 1: preprocessing -> in-progress
127.0.0.1 - - [10/Dec/2025 05:20:45] "POST /status/story HTTP/1.1" 200 -
[STATUS] Story 1: chunking -> in-progress
127.0.0.1 - - [10/Dec/2025 05:20:45] "POST /status/story HTTP/1.1" 200 -

==================================================
Processing: ./tests/examples-pipeline/epub/trilogy-wishes-2.epub
[96m[TIME] [93mtask_01_convert_epub took 2.484s[0m
[96m[TIME] [93mtask_02_parse_chapters took 0.047s[0m
[96m[TIME] [93mtask_03_chunk_story took 0.019s[0m

=== STORY SUMMARY ===
Total chunks: 254
[96m[TIME] [93mpipeline_A took 2.650s[0m
[STATUS] Story 1: preprocessing -> completed
127.0.0.1 - - [10/Dec/2025 05:20:47] "POST /status/story HTTP/1.1" 200 -
[STATUS] Story 1: chunking -> completed
127.0.0.1 - - [10/Dec/2025 05:20:47] "POST /status/story HTTP/1.1" 200 -

Chunk details:
  index: 140

The latch rattled, and clicked. Then the flap of the letter-box lifted itselfâ€”every one saw it by the flickering light of the gas-lamp that shone through the leafless lime-tree by the gateâ€”a golden eye seemed to wink at them through the letter-slit, and a cautious beak whisperedâ€”
â€˜Are you alone?â€™
â€˜Itâ€™s the Phoenix,â€™ said every one, in a voice so joyous, and so full of relief, as to be a sort of whispered shout.
â€˜Hush!â€™ said the voice from the letter-box slit. â€˜Your slaves have gone a-merry-making. The latch of this portal is too stiff for my beak. But at the sideâ€”the little window above the shelf whereon your bread liesâ€”it is not fastened.â€™
â€˜Righto!â€™ said Cyril.
And Anthea added, â€˜I wish youâ€™d meet us there, dear Phoenix.â€™
The children crept round to the pantry window. It is at the side of the house, and there is a green gate labelled â€˜Tradesmenâ€™s Entranceâ€™, which is always kept bolted. But if you get one foot on the fence between you and next door, and one on the handle of the gate, you are over before you know where you are. This, at least, was the experience of Cyril and Robert, and even, if the truth must be told, of Anthea and Jane. So in almost no time all four were in the narrow gravelled passage that runs between that house and the next.
[96m[TIME] [93mtask_11_send_chunk took 0.037s[0m
    [Inserted chunk into Mongo with chunk_id: story-1_book-2_chapter-12_p.20963]
[96m[TIME] [93mtask_12_relation_extraction[textacy] took 1.818s[0m

NLP output:
{'s': 'flap', 'r': 'lifted', 'o': 'itself'}
{'s': 'one', 'r': 'saw', 'o': 'it'}
{'s': 'eye', 'r': 'seemed', 'o': 'to wink at them through the letter - slit'}
{'s': 'beak', 'r': 'whispered', 'o': 'Are you alone'}
{'s': 'slaves', 'r': 'have gone', 'o': 'merry making'}
{'s': 'it', 'r': 'is not fastened', 'o': 'â€˜ Righto ! â€™'}
{'s': 'I', 'r': 'wish', 'o': 'you'}
{'s': 'which', 'r': 'is kept', 'o': 'bolted'}
{'s': 'you', 'r': 'get', 'o': 'foot'}

[96m[TIME] [93mtask_14_validate_llm[openai] took 142.012s[0m

    LLM prompt:
Here are some semantic triples extracted from a story chunk:
{'s': 'flap', 'r': 'lifted', 'o': 'itself'}
{'s': 'one', 'r': 'saw', 'o': 'it'}
{'s': 'eye', 'r': 'seemed', 'o': 'to wink at them through the letter - slit'}
{'s': 'beak', 'r': 'whispered', 'o': 'Are you alone'}
{'s': 'slaves', 'r': 'have gone', 'o': 'merry making'}
{'s': 'it', 'r': 'is not fastened', 'o': 'â€˜ Righto ! â€™'}
{'s': 'I', 'r': 'wish', 'o': 'you'}
{'s': 'which', 'r': 'is kept', 'o': 'bolted'}
{'s': 'you', 'r': 'get', 'o': 'foot'}

And here is the original text:
The latch rattled, and clicked. Then the flap of the letter-box lifted itselfâ€”every one saw it by the flickering light of the gas-lamp that shone through the leafless lime-tree by the gateâ€”a golden eye seemed to wink at them through the letter-slit, and a cautious beak whisperedâ€”
â€˜Are you alone?â€™
â€˜Itâ€™s the Phoenix,â€™ said every one, in a voice so joyous, and so full of relief, as to be a sort of whispered shout.
â€˜Hush!â€™ said the voice from the letter-box slit. â€˜Your slaves have gone a-merry-making. The latch of this portal is too stiff for my beak. But at the sideâ€”the little window above the shelf whereon your bread liesâ€”it is not fastened.â€™
â€˜Righto!â€™ said Cyril.
And Anthea added, â€˜I wish youâ€™d meet us there, dear Phoenix.â€™
The children crept round to the pantry window. It is at the side of the house, and there is a green gate labelled â€˜Tradesmenâ€™s Entranceâ€™, which is always kept bolted. But if you get one foot on the fence between you and next door, and one on the handle of the gate, you are over before you know where you are. This, at least, was the experience of Cyril and Robert, and even, if the truth must be told, of Anthea and Jane. So in almost no time all four were in the narrow gravelled passage that runs between that house and the next.

Output JSON with keys: s (subject), r (relation), o (object).
Remove nonsensical triples but otherwise retain all relevant entries, and add new ones to encapsulate events, dialogue, and core meaning where applicable.

    LLM output:
[
  {"s": "letter-box latch", "r": "rattled and clicked", "o": "audibly"},
  {"s": "letter-box flap", "r": "lifted", "o": "itself"},
  {"s": "everyone", "r": "saw", "o": "the letter-box flap lift"},
  {"s": "gas-lamp", "r": "shone through", "o": "the leafless lime-tree"},
  {"s": "gas-lamp light", "r": "flickered", "o": "by the gate"},
  {"s": "a golden eye", "r": "seemed to wink at", "o": "the children through the letter-box slit"},
  {"s": "a golden eye", "r": "appeared in", "o": "the letter-box slit"},
  {"s": "Phoenix", "r": "was at", "o": "the letter-box slit"},
  {"s": "Phoenix", "r": "spoke through", "o": "the letter-box slit"},
  {"s": "Phoenix's beak", "r": "whispered", "o": "Are you alone?"},
  {"s": "voice from the letter-box slit", "r": "said", "o": "Hush!"},
  {"s": "everyone", "r": "said", "o": "It's the Phoenix"},
  {"s": "everyone", "r": "felt", "o": "joyous relief"},
  {"s": "Phoenix", "r": "said", "o": "Your servants have gone a-merry-making"},
  {"s": "door latch", "r": "is too stiff for", "o": "the Phoenix's beak"},
  {"s": "little window above the bread-shelf", "r": "is not", "o": "fastened"},
  {"s": "Cyril", "r": "said", "o": "Righto!"},
  {"s": "Anthea", "r": "wished", "o": "the Phoenix would meet them at the side window"},
  {"s": "the children", "r": "crept to", "o": "the pantry window"},
  {"s": "pantry window", "r": "is at", "o": "the side of the house"},
  {"s": "green gate", "r": "is labelled", "o": "Tradesmen's Entrance"},
  {"s": "Tradesmen's Entrance gate", "r": "is always kept", "o": "bolted"},
  {"s": "the children", "r": "climbed over", "o": "the gate by stepping on the fence and the gate handle"},
  {"s": "Cyril and Robert", "r": "used", "o": "this method to get over the gate"},
  {"s": "Anthea and Jane", "r": "also used", "o": "this method to get over the gate"},
  {"s": "the four children", "r": "were soon in", "o": "the narrow gravelled passage between the houses"},
  {"s": "the children", "r": "recognized", "o": "the Phoenix"}
]

==================================================

[96m[TIME] [93mtask_16_moderate_triples_llm[drop] took 5.204s[0m

Moderation removed 0 triples
Valid JSON
[96m[TIME] [93mpipeline_B took 149.263s[0m
Checkpoint saved to ./datasets/checkpoint.pkl
[STATUS] Chunk story-1_book-2_chapter-12_p.20963: relation_extraction -> in-progress
127.0.0.1 - - [10/Dec/2025 05:23:17] "POST /status/chunk HTTP/1.1" 200 -
[STATUS] Chunk story-1_book-2_chapter-12_p.20963: llm_inference -> in-progress
127.0.0.1 - - [10/Dec/2025 05:23:17] "POST /status/chunk HTTP/1.1" 200 -
[STATUS] Chunk story-1_book-2_chapter-12_p.20963: relation_extraction -> completed
127.0.0.1 - - [10/Dec/2025 05:23:17] "POST /status/chunk HTTP/1.1" 200 -
[STATUS] Chunk story-1_book-2_chapter-12_p.20963: llm_inference -> completed
127.0.0.1 - - [10/Dec/2025 05:23:17] "POST /status/chunk HTTP/1.1" 200 -
[STATUS] Chunk story-1_book-2_chapter-12_p.20963: graph_verbalization -> in-progress
127.0.0.1 - - [10/Dec/2025 05:23:17] "POST /status/chunk HTTP/1.1" 200 -
letter-box latch rattled and clicked audibly
letter-box flap lifted itself
everyone saw the letter-box flap lift
gas-lamp shone through the leafless lime-tree
gas-lamp light flickered by the gate
a golden eye seemed to wink at the children through the letter-box slit
a golden eye appeared in the letter-box slit
Phoenix was at the letter-box slit
Phoenix spoke through the letter-box slit
Phoenix's beak whispered Are you alone?
voice from the letter-box slit said Hush!
everyone said It's the Phoenix
everyone felt joyous relief
Phoenix said Your servants have gone a-merry-making
door latch is too stiff for the Phoenix's beak
little window above the bread-shelf is not fastened
Cyril said Righto!
Anthea wished the Phoenix would meet them at the side window
the children crept to the pantry window
pantry window is at the side of the house
green gate is labelled Tradesmen's Entrance
Tradesmen's Entrance gate is always kept bolted
the children climbed over the gate by stepping on the fence and the gate handle
Cyril and Robert used this method to get over the gate
Anthea and Jane also used this method to get over the gate
the four children were soon in the narrow gravelled passage between the houses
the children recognized the Phoenix
[96m[TIME] [93mtask_20_send_triples took 4.936s[0m
[96m[TIME] [93mtask_22_fetch_subgraph[popular] took 0.301s[0m
[96m[TIME] [93mtask_23_verbalize_triples[raw] took 0.001s[0m

Triples which best represent the graph:
everyone SAW letter_box_flap_lift
golden_eye SEEMED_TO_WINK_AT children_through_letter_box_slit
golden_eye APPEARED_IN letter_box_slit
Phoenix SPOKE_THROUGH letter_box_slit
Phoenix WAS_AT letter_box_slit
children RECOGNIZED Phoenix
everyone SAID s_Phoenix
everyone FELT joyous_relief
Phoenix SAID servants_have_gone_merry_making
children CREPT_TO pantry_window
children CLIMBED_OVER gate_by_stepping_on_fence_and_gate_handle
[96m[TIME] [93mpipeline_C took 5.321s[0m
[STATUS] Chunk story-1_book-2_chapter-12_p.20963: graph_verbalization -> completed
127.0.0.1 - - [10/Dec/2025 05:23:22] "POST /status/chunk HTTP/1.1" 200 -
[STATUS] Story 1: summarization -> in-progress
127.0.0.1 - - [10/Dec/2025 05:23:22] "POST /status/story HTTP/1.1" 200 -
[STATUS] Chunk story-1_book-2_chapter-12_p.20963: summarization -> in-progress
127.0.0.1 - - [10/Dec/2025 05:23:22] "POST /status/chunk HTTP/1.1" 200 -
[96m[TIME] [93mtask_30_summarize_llm[text] took 20.205s[0m

Generated summary:
The Phoenix peers through the letterbox, asks if the children are alone, and tells them the servants are out, the door latch is too stiff, and the pantry window is unfastened. The children agree to meet it there, climb over the bolted tradesmenâ€™s gate, and quickly reach the narrow side passage by the pantry window.
[96m[TIME] [93mtask_31_send_summary took 0.002s[0m
    [Wrote summary to Mongo with chunk_id: story-1_book-2_chapter-12_p.20963]
[96m[TIME] [93mpipeline_D took 20.261s[0m
[STATUS] Story 1: summarization -> completed
127.0.0.1 - - [10/Dec/2025 05:23:42] "POST /status/story HTTP/1.1" 200 -
[STATUS] Chunk story-1_book-2_chapter-12_p.20963: summarization -> completed
127.0.0.1 - - [10/Dec/2025 05:23:42] "POST /status/chunk HTTP/1.1" 200 -
[ASSIGNED] chunk 'story-1_book-2_chapter-12_p.20963' to worker questeval: using database 'conan_capstone' and collection 'story_chunks'
127.0.0.1 - - [10/Dec/2025 05:23:42] "POST /process_story HTTP/1.1" 200 -
[CALLBACK] chunk_id=story-1_book-2_chapter-12_p.20963, task=questeval, status=startedTriggered questeval: {'assigned': 1, 'status': 'tasks_assigned', 'story_id': 1, 'task_type': 'questeval', 'total_chunks': 1}

172.18.0.2 - - [10/Dec/2025 05:23:42] "POST /callback HTTP/1.1" 200 -
[ASSIGNED] chunk 'story-1_book-2_chapter-12_p.20963' to worker bookscore: using database 'conan_capstone' and collection 'story_chunks'
127.0.0.1 - - [10/Dec/2025 05:23:42] "POST /process_story HTTP/1.1" 200 -
Triggered bookscore: {'assigned': 1, 'status': 'tasks_assigned', 'story_id': 1, 'task_type': 'bookscore', 'total_chunks': 1}

=== TIMING SUMMARY ===
                                      calls       total         avg         min         max
function                                                                                   
pipeline_A                                1    2.649675    2.649675    2.649675    2.649675
pipeline_B                                1  149.262965  149.262965  149.262965  149.262965
pipeline_C                                1    5.321179    5.321179    5.321179    5.321179
pipeline_D                                1   20.260667   20.260667   20.260667   20.260667
task_01_convert_epub                      1    2.483987    2.483987    2.483987    2.483987
task_02_parse_chapters                    1    0.047024    0.047024    0.047024    0.047024
task_03_chunk_story                       1    0.019111    0.019111    0.019111    0.019111
task_11_send_chunk                        1    0.037272    0.037272    0.037272    0.037272
task_12_relation_extraction[textacy]      1    1.818263    1.818263    1.818263    1.818263
task_14_validate_llm[openai]              1  142.011833  142.011833  142.011833  142.011833
task_16_moderate_triples_llm[drop]        1    5.203606    5.203606    5.203606    5.203606
task_20_send_triples                      1    4.936485    4.936485    4.936485    4.936485
task_22_fetch_subgraph[popular]           1    0.300608    0.300608    0.300608    0.300608
task_23_verbalize_triples[raw]            1    0.000751    0.000751    0.000751    0.000751
task_30_summarize_llm[text]               1   20.205142   20.205142   20.205142   20.205142
task_31_send_summary                      1    0.001681    0.001681    0.001681    0.001681

Total execution time: 354.560s
[CALLBACK] chunk_id=story-1_book-2_chapter-12_p.20963, task=bookscore, status=started
172.18.0.3 - - [10/Dec/2025 05:23:42] "POST /callback HTTP/1.1" 200 -
[96m[DUMP] [93mSaved time records to './logs/elapsed_time.csv'[0m
[90m[CHART] [93mSaved chart 'Average Function Runtime Across Runs' to ./logs/charts/avg_runtime.png[0m
Initial processing complete. Server listening for additional requests from Blazor...
Press Ctrl+C to stop.
[CALLBACK] chunk_id=story-1_book-2_chapter-12_p.20963, task=bookscore, status=completed
[96m[TIME] [93mworker_metric_bookscore took 5.161s[0m
[STORY COMPLETE] All chunks completed metric_bookscore for story 1

=== TIMING SUMMARY ===
                                      calls       total         avg         min         max
function                                                                                   
pipeline_A                                1    2.649675    2.649675    2.649675    2.649675
pipeline_B                                1  149.262965  149.262965  149.262965  149.262965
pipeline_C                                1    5.321179    5.321179    5.321179    5.321179
pipeline_D                                1   20.260667   20.260667   20.260667   20.260667
task_01_convert_epub                      1    2.483987    2.483987    2.483987    2.483987
task_02_parse_chapters                    1    0.047024    0.047024    0.047024    0.047024
task_03_chunk_story                       1    0.019111    0.019111    0.019111    0.019111
task_11_send_chunk                        1    0.037272    0.037272    0.037272    0.037272
task_12_relation_extraction[textacy]      1    1.818263    1.818263    1.818263    1.818263
task_14_validate_llm[openai]              1  142.011833  142.011833  142.011833  142.011833
task_16_moderate_triples_llm[drop]        1    5.203606    5.203606    5.203606    5.203606
task_20_send_triples                      1    4.936485    4.936485    4.936485    4.936485
task_22_fetch_subgraph[popular]           1    0.300608    0.300608    0.300608    0.300608
task_23_verbalize_triples[raw]            1    0.000751    0.000751    0.000751    0.000751
task_30_summarize_llm[text]               1   20.205142   20.205142   20.205142   20.205142
task_31_send_summary                      1    0.001681    0.001681    0.001681    0.001681
worker_metric_bookscore                   1    5.161327    5.161327    5.161327    5.161327

Total execution time: 359.722s
[96m[DUMP] [93mSaved time records to './logs/elapsed_time.csv'[0m
[90m[CHART] [93mSaved chart 'Average Function Runtime Across Runs' to ./logs/charts/avg_runtime.png[0m
172.18.0.3 - - [10/Dec/2025 05:23:48] "POST /callback HTTP/1.1" 200 -
[CALLBACK] chunk_id=story-1_book-2_chapter-12_p.20963, task=questeval, status=completed
[96m[TIME] [93mworker_metric_questeval took 169.167s[0m
[STORY COMPLETE] All chunks completed metric_questeval for story 1

=== TIMING SUMMARY ===
                                      calls       total         avg         min         max
function                                                                                   
pipeline_A                                1    2.649675    2.649675    2.649675    2.649675
pipeline_B                                1  149.262965  149.262965  149.262965  149.262965
pipeline_C                                1    5.321179    5.321179    5.321179    5.321179
pipeline_D                                1   20.260667   20.260667   20.260667   20.260667
task_01_convert_epub                      1    2.483987    2.483987    2.483987    2.483987
task_02_parse_chapters                    1    0.047024    0.047024    0.047024    0.047024
task_03_chunk_story                       1    0.019111    0.019111    0.019111    0.019111
task_11_send_chunk                        1    0.037272    0.037272    0.037272    0.037272
task_12_relation_extraction[textacy]      1    1.818263    1.818263    1.818263    1.818263
task_14_validate_llm[openai]              1  142.011833  142.011833  142.011833  142.011833
task_16_moderate_triples_llm[drop]        1    5.203606    5.203606    5.203606    5.203606
task_20_send_triples                      1    4.936485    4.936485    4.936485    4.936485
task_22_fetch_subgraph[popular]           1    0.300608    0.300608    0.300608    0.300608
task_23_verbalize_triples[raw]            1    0.000751    0.000751    0.000751    0.000751
task_30_summarize_llm[text]               1   20.205142   20.205142   20.205142   20.205142
task_31_send_summary                      1    0.001681    0.001681    0.001681    0.001681
worker_metric_bookscore                   1    5.161327    5.161327    5.161327    5.161327
worker_metric_questeval                   1  169.167460  169.167460  169.167460  169.167460

Total execution time: 528.889s
[96m[DUMP] [93mSaved time records to './logs/elapsed_time.csv'[0m
[90m[CHART] [93mSaved chart 'Average Function Runtime Across Runs' to ./logs/charts/avg_runtime.png[0m
[96m[TIME] [93mtask_45_eval_coverage took 0.865s[0m
[96m[TIME] [93mtask_45_eval_rouge took 1.813s[0m
Downloading builder script: 0.00B [00:00, ?B/s]Downloading builder script: 7.95kB [00:00, 19.1MB/s]
[96m[TIME] [93mtask_45_eval_bertscore took 20.075s[0m
[96m[TIME] [93mtask_45_eval_ngrams took 0.022s[0m
[96m[TIME] [93mtask_45_eval_jsd took 0.009s[0m
[96m[TIME] [93mtask_45_eval_ncd took 0.000s[0m
[96m[TIME] [93mtask_45_eval_salience took 0.014s[0m
[96m[TIME] [93mtask_45_eval_faithfulness took 28.833s[0m
[96m[TIME] [93mtask_45_eval_readability took 1.494s[0m
[96m[TIME] [93mtask_45_eval_sentence_coherence took 7.591s[0m
[96m[TIME] [93mtask_45_eval_entity_grid took 0.543s[0m
[96m[TIME] [93mtask_45_eval_diversity took 0.000s[0m
[96m[TIME] [93mtask_45_eval_stopwords took 0.002s[0m
Downloading builder script: 0.00B [00:00, ?B/s]Downloading builder script: 6.14kB [00:00, 3.72MB/s]
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Sending payload to Blazor at http://blazor_service:5055/api/metrics
POST succeeded
{'bookID': '2', 'bookTitle': 'The Phoenix and the Carpet', 'summaryText': 'The Phoenix peers through the letterbox, asks if the children are alone, and tells them the servants are out, the door latch is too stiff, and the pantry window is unfastened. The children agree to meet it there, climb over the bolted tradesmenâ€™s gate, and quickly reach the narrow side passage by the pantry window.', 'goldSummaryText': 'The latch rattled, and clicked. Then the flap of the letter-box lifted itselfâ€”every one saw it by the flickering light of the gas-lamp that shone through the leafless lime-tree by the gateâ€”a golden eye seemed to wink at them through the letter-slit, and a cautious beak whisperedâ€”\nâ€˜Are you alone?â€™\nâ€˜Itâ€™s the Phoenix,â€™ said every one, in a voice so joyous, and so full of relief, as to be a sort of whispered shout.\nâ€˜Hush!â€™ said the voice from the letter-box slit. â€˜Your slaves have gone a-merry-making. The latch of this portal is too stiff for my beak. But at the sideâ€”the little window above the shelf whereon your bread liesâ€”it i', 'metrics': {'prF1Metrics': [{'name': 'BERTScore', 'precision': 0.861991286277771, 'recall': 0.8211845755577087, 'f1Score': 0.8410933613777161}], 'qa': {'qaItems': [{'question': 'UNKNOWN', 'goldAnswer': 'UNKNOWN', 'generatedAnswer': 'UNKNOWN', 'isCorrect': False, 'accuracy': 0}, {'question': 'UNKNOWN', 'goldAnswer': 'UNKNOWN', 'generatedAnswer': 'UNKNOWN', 'isCorrect': False, 'accuracy': 0}], 'averageAccuracy': 0}, 'scalarMetrics': [{'name': 'BooookScore (Chang 2024)', 'value': 1}, {'name': 'QuestEval (Scialom 2021)', 'value': 0.28232510738720984}, {'name': 'ROUGE-1', 'value': 0.3222222222222222}, {'name': 'ROUGE-2', 'value': 0.056179775280898875}, {'name': 'ROUGE-L', 'value': 0.18888888888888888}, {'name': 'ROUGE-Lsum', 'value': 0.26666666666666666}]}, 'qaResults': []}
[96m[TIME] [93mtask_40_post_payload took 31.057s[0m

Output sent to web app.
[96m[TIME] [93mpipeline_E took 92.334s[0m
[PIPELINE FINALIZED] Story 1 fully processed

=== TIMING SUMMARY ===
                                      calls       total         avg         min         max
function                                                                                   
pipeline_A                                1    2.649675    2.649675    2.649675    2.649675
pipeline_B                                1  149.262965  149.262965  149.262965  149.262965
pipeline_C                                1    5.321179    5.321179    5.321179    5.321179
pipeline_D                                1   20.260667   20.260667   20.260667   20.260667
pipeline_E                                1   92.333991   92.333991   92.333991   92.333991
task_01_convert_epub                      1    2.483987    2.483987    2.483987    2.483987
task_02_parse_chapters                    1    0.047024    0.047024    0.047024    0.047024
task_03_chunk_story                       1    0.019111    0.019111    0.019111    0.019111
task_11_send_chunk                        1    0.037272    0.037272    0.037272    0.037272
task_12_relation_extraction[textacy]      1    1.818263    1.818263    1.818263    1.818263
task_14_validate_llm[openai]              1  142.011833  142.011833  142.011833  142.011833
task_16_moderate_triples_llm[drop]        1    5.203606    5.203606    5.203606    5.203606
task_20_send_triples                      1    4.936485    4.936485    4.936485    4.936485
task_22_fetch_subgraph[popular]           1    0.300608    0.300608    0.300608    0.300608
task_23_verbalize_triples[raw]            1    0.000751    0.000751    0.000751    0.000751
task_30_summarize_llm[text]               1   20.205142   20.205142   20.205142   20.205142
task_31_send_summary                      1    0.001681    0.001681    0.001681    0.001681
task_40_post_payload                      1   31.057395   31.057395   31.057395   31.057395
task_45_eval_bertscore                    1   20.075177   20.075177   20.075177   20.075177
task_45_eval_coverage                     1    0.865127    0.865127    0.865127    0.865127
task_45_eval_diversity                    1    0.000282    0.000282    0.000282    0.000282
task_45_eval_entity_grid                  1    0.542896    0.542896    0.542896    0.542896
task_45_eval_faithfulness                 1   28.833140   28.833140   28.833140   28.833140
task_45_eval_jsd                          1    0.008855    0.008855    0.008855    0.008855
task_45_eval_ncd                          1    0.000130    0.000130    0.000130    0.000130
task_45_eval_ngrams                       1    0.022033    0.022033    0.022033    0.022033
task_45_eval_readability                  1    1.494425    1.494425    1.494425    1.494425
task_45_eval_rouge                        1    1.812882    1.812882    1.812882    1.812882
task_45_eval_salience                     1    0.013577    0.013577    0.013577    0.013577
task_45_eval_sentence_coherence           1    7.591373    7.591373    7.591373    7.591373
task_45_eval_stopwords                    1    0.001762    0.001762    0.001762    0.001762
worker_metric_bookscore                   1    5.161327    5.161327    5.161327    5.161327
worker_metric_questeval                   1  169.167460  169.167460  169.167460  169.167460

Total execution time: 713.542s
[96m[DUMP] [93mSaved time records to './logs/elapsed_time.csv'[0m
[90m[CHART] [93mSaved chart 'Average Function Runtime Across Runs' to ./logs/charts/avg_runtime.png[0m
[90m[CHART] [93mSaved chart 'Saved summary metrics CSV' to ./logs/metrics/chunk_summary.csv[0m
172.18.0.2 - - [10/Dec/2025 05:28:05] "POST /callback HTTP/1.1" 200 -
INFO:werkzeug:172.18.0.2 - - [10/Dec/2025 05:28:05] "POST /callback HTTP/1.1" 200 -
