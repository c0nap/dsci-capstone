conanp@RPI-conanp:/mnt/c/dsci-cap/capstone$ docker logs container-python
Deleted old chunks...
 * Serving Flask app 'src.core.boss'
 * Debug mode: off
WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5054
 * Running on http://172.17.0.5:5054
Press CTRL+C to quit
[STATUS] Story 1: preprocessing -> in-progress
127.0.0.1 - - [10/Dec/2025 04:38:38] "POST /status/story HTTP/1.1" 200 -
[STATUS] Story 1: chunking -> in-progress
127.0.0.1 - - [10/Dec/2025 04:38:38] "POST /status/story HTTP/1.1" 200 -

==================================================
Processing: ./tests/examples-pipeline/epub/trilogy-wishes-2.epub
[TIME] task_01_convert_epub took 2.346s
[TIME] task_02_parse_chapters took 0.034s
[TIME] task_03_chunk_story took 0.019s

=== STORY SUMMARY ===
Total chunks: 254
[TIME] pipeline_A took 2.488s
[STATUS] Story 1: preprocessing -> completed
127.0.0.1 - - [10/Dec/2025 04:38:41] "POST /status/story HTTP/1.1" 200 -
[STATUS] Story 1: chunking -> completed
127.0.0.1 - - [10/Dec/2025 04:38:41] "POST /status/story HTTP/1.1" 200 -

Chunk details:
  index: 140

The latch rattled, and clicked. Then the flap of the letter-box lifted itself—every one saw it by the flickering light of the gas-lamp that shone through the leafless lime-tree by the gate—a golden eye seemed to wink at them through the letter-slit, and a cautious beak whispered—
‘Are you alone?’
‘It’s the Phoenix,’ said every one, in a voice so joyous, and so full of relief, as to be a sort of whispered shout.
‘Hush!’ said the voice from the letter-box slit. ‘Your slaves have gone a-merry-making. The latch of this portal is too stiff for my beak. But at the side—the little window above the shelf whereon your bread lies—it is not fastened.’
‘Righto!’ said Cyril.
And Anthea added, ‘I wish you’d meet us there, dear Phoenix.’
The children crept round to the pantry window. It is at the side of the house, and there is a green gate labelled ‘Tradesmen’s Entrance’, which is always kept bolted. But if you get one foot on the fence between you and next door, and one on the handle of the gate, you are over before you know where you are. This, at least, was the experience of Cyril and Robert, and even, if the truth must be told, of Anthea and Jane. So in almost no time all four were in the narrow gravelled passage that runs between that house and the next.
[TIME] task_11_send_chunk took 0.031s
    [Inserted chunk into Mongo with chunk_id: story-1_book-2_chapter-12_p.20963]
[TIME] task_12_relation_extraction[textacy] took 1.556s

NLP output:
{'s': 'flap', 'r': 'lifted', 'o': 'itself'}
{'s': 'one', 'r': 'saw', 'o': 'it'}
{'s': 'eye', 'r': 'seemed', 'o': 'to wink at them through the letter - slit'}
{'s': 'beak', 'r': 'whispered', 'o': 'Are you alone'}
{'s': 'slaves', 'r': 'have gone', 'o': 'merry making'}
{'s': 'it', 'r': 'is not fastened', 'o': '‘ Righto ! ’'}
{'s': 'I', 'r': 'wish', 'o': 'you'}
{'s': 'which', 'r': 'is kept', 'o': 'bolted'}
{'s': 'you', 'r': 'get', 'o': 'foot'}

[TIME] task_14_validate_llm[openai] took 5.136s

    LLM prompt:
Here are some semantic triples extracted from a story chunk:
{'s': 'flap', 'r': 'lifted', 'o': 'itself'}
{'s': 'one', 'r': 'saw', 'o': 'it'}
{'s': 'eye', 'r': 'seemed', 'o': 'to wink at them through the letter - slit'}
{'s': 'beak', 'r': 'whispered', 'o': 'Are you alone'}
{'s': 'slaves', 'r': 'have gone', 'o': 'merry making'}
{'s': 'it', 'r': 'is not fastened', 'o': '‘ Righto ! ’'}
{'s': 'I', 'r': 'wish', 'o': 'you'}
{'s': 'which', 'r': 'is kept', 'o': 'bolted'}
{'s': 'you', 'r': 'get', 'o': 'foot'}

And here is the original text:
The latch rattled, and clicked. Then the flap of the letter-box lifted itself—every one saw it by the flickering light of the gas-lamp that shone through the leafless lime-tree by the gate—a golden eye seemed to wink at them through the letter-slit, and a cautious beak whispered—
‘Are you alone?’
‘It’s the Phoenix,’ said every one, in a voice so joyous, and so full of relief, as to be a sort of whispered shout.
‘Hush!’ said the voice from the letter-box slit. ‘Your slaves have gone a-merry-making. The latch of this portal is too stiff for my beak. But at the side—the little window above the shelf whereon your bread lies—it is not fastened.’
‘Righto!’ said Cyril.
And Anthea added, ‘I wish you’d meet us there, dear Phoenix.’
The children crept round to the pantry window. It is at the side of the house, and there is a green gate labelled ‘Tradesmen’s Entrance’, which is always kept bolted. But if you get one foot on the fence between you and next door, and one on the handle of the gate, you are over before you know where you are. This, at least, was the experience of Cyril and Robert, and even, if the truth must be told, of Anthea and Jane. So in almost no time all four were in the narrow gravelled passage that runs between that house and the next.

Output JSON with keys: s (subject), r (relation), o (object).
Remove nonsensical triples but otherwise retain all relevant entries, and add new ones to encapsulate events, dialogue, and core meaning where applicable.

    LLM output:
[
  {"s": "flap", "r": "lifted", "o": "itself"},
  {"s": "one", "r": "saw", "o": "it"},
  {"s": "eye", "r": "seemed", "o": "to wink at them through the letter - slit"},
  {"s": "beak", "r": "whispered", "o": "Are you alone"},
  {"s": "slaves", "r": "have gone", "o": "merry making"},
  {"s": "it", "r": "is not fastened", "o": "‘ Righto ! ’"},
  {"s": "I", "r": "wish", "o": "you"},
  {"s": "which", "r": "is kept", "o": "bolted"},
  {"s": "you", "r": "get", "o": "foot"},
  {"s": "latch", "r": "rattled", "o": "and clicked"},
  {"s": "flap of the letter-box", "r": "lifted", "o": "itself"},
  {"s": "letter-box", "r": "had a", "o": "leafless lime-tree by the gate (in sight)"},
  {"s": "golden eye", "r": "seemed", "o": "to wink through the letter-slit"},
  {"s": "doorway", "r": "contained", "o": "the voice from the letter-box slit"},
  {"s": "Phoenix", "r": "is", "o": "the object of the children’s exclamation"},
  {"s": "Cyril", "r": "says", "o": "Righto!"},
  {"s": "Anthea", "r": "adds", "o": "I wish you’d meet us there, dear Phoenix"},
  {"s": "children", "r": "crept", "o": "round to the pantry window"},
  {"s": "pantry window", "r": "is at the side of", "o": "the house"},
  {"s": "Tradesmen’s Entrance", "r": "is labelled", "o": "on the green gate"},
  {"s": "gate", "r": "is kept", "o": "bolted"},
  {"s": "foot", "r": "on the fence", "o": "between you and next door"},
  {"s": "handlе of the gate", "r": "is on", "o": "the fence"},
  {"s": "you", "r": "are over", "o": "before you know where you are"},
  {"s": "Cyril", "r": "and", "o": "Robert (and Anthea and Jane)"},
  {"s": "Anthea", "r": "and", "o": "Jane"},
  {"s": "four", "r": "are in", "o": "the narrow gravelled passage between that house and the next"}
]

==================================================

[TIME] task_16_moderate_triples_llm[drop] took 1.620s

Moderation removed 0 triples
Valid JSON
[TIME] pipeline_B took 8.544s
Checkpoint saved to ./datasets/checkpoint.pkl
[STATUS] Chunk story-1_book-2_chapter-12_p.20963: relation_extraction -> in-progress
127.0.0.1 - - [10/Dec/2025 04:38:50] "POST /status/chunk HTTP/1.1" 200 -
[STATUS] Chunk story-1_book-2_chapter-12_p.20963: llm_inference -> in-progress
127.0.0.1 - - [10/Dec/2025 04:38:50] "POST /status/chunk HTTP/1.1" 200 -
[STATUS] Chunk story-1_book-2_chapter-12_p.20963: relation_extraction -> completed
127.0.0.1 - - [10/Dec/2025 04:38:50] "POST /status/chunk HTTP/1.1" 200 -
[STATUS] Chunk story-1_book-2_chapter-12_p.20963: llm_inference -> completed
127.0.0.1 - - [10/Dec/2025 04:38:50] "POST /status/chunk HTTP/1.1" 200 -
[STATUS] Chunk story-1_book-2_chapter-12_p.20963: graph_verbalization -> in-progress
127.0.0.1 - - [10/Dec/2025 04:38:50] "POST /status/chunk HTTP/1.1" 200 -
flap lifted itself
one saw it
eye seemed to wink at them through the letter - slit
beak whispered Are you alone
slaves have gone merry making
it is not fastened ‘ Righto ! ’
I wish you
which is kept bolted
you get foot
latch rattled and clicked
flap of the letter-box lifted itself
letter-box had a leafless lime-tree by the gate (in sight)
golden eye seemed to wink through the letter-slit
doorway contained the voice from the letter-box slit
Phoenix is the object of the children’s exclamation
Cyril says Righto!
Anthea adds I wish you’d meet us there, dear Phoenix
children crept round to the pantry window
pantry window is at the side of the house
Tradesmen’s Entrance is labelled on the green gate
gate is kept bolted
foot on the fence between you and next door
handlе of the gate is on the fence
you are over before you know where you are
Cyril and Robert (and Anthea and Jane)
Anthea and Jane
four are in the narrow gravelled passage between that house and the next
[TIME] task_20_send_triples took 5.702s
[TIME] task_22_fetch_subgraph[popular] took 0.325s
[TIME] task_23_verbalize_triples[raw] took 0.000s

Triples which best represent the graph:
you GET foot
foot ON_THE_FENCE between_and_next_door
you ARE_OVER before_know_where_are
[TIME] pipeline_C took 6.120s
[STATUS] Chunk story-1_book-2_chapter-12_p.20963: graph_verbalization -> completed
127.0.0.1 - - [10/Dec/2025 04:38:56] "POST /status/chunk HTTP/1.1" 200 -
[STATUS] Story 1: summarization -> in-progress
127.0.0.1 - - [10/Dec/2025 04:38:56] "POST /status/story HTTP/1.1" 200 -
[STATUS] Chunk story-1_book-2_chapter-12_p.20963: summarization -> in-progress
127.0.0.1 - - [10/Dec/2025 04:38:56] "POST /status/chunk HTTP/1.1" 200 -
[TIME] task_30_summarize_llm[triples] took 1.492s

Generated summary:
Foot is on the fence between the speaker and the neighboring house, and the speaker is over a place where they do not yet know what is there.
[TIME] task_31_send_summary took 0.002s
    [Wrote summary to Mongo with chunk_id: story-1_book-2_chapter-12_p.20963]
[TIME] pipeline_D took 1.548s
[STATUS] Story 1: summarization -> completed
127.0.0.1 - - [10/Dec/2025 04:38:57] "POST /status/story HTTP/1.1" 200 -
[STATUS] Chunk story-1_book-2_chapter-12_p.20963: summarization -> completed
127.0.0.1 - - [10/Dec/2025 04:38:57] "POST /status/chunk HTTP/1.1" 200 -
[ASSIGNED] chunk 'story-1_book-2_chapter-12_p.20963' to worker questeval: using database 'conan_capstone' and collection 'story_chunks'
127.0.0.1 - - [10/Dec/2025 04:38:57] "POST /process_story HTTP/1.1" 200 -
Triggered questeval: {'assigned': 1, 'status': 'tasks_assigned', 'story_id': 1, 'task_type': 'questeval', 'total_chunks': 1}
[CALLBACK] chunk_id=story-1_book-2_chapter-12_p.20963, task=questeval, status=started
172.18.0.2 - - [10/Dec/2025 04:38:57] "POST /callback HTTP/1.1" 200 -
[ASSIGNED] chunk 'story-1_book-2_chapter-12_p.20963' to worker bookscore: using database 'conan_capstone' and collection 'story_chunks'
127.0.0.1 - - [10/Dec/2025 04:38:57] "POST /process_story HTTP/1.1" 200 -
Triggered bookscore: {'assigned': 1, 'status': 'tasks_assigned', 'story_id': 1, 'task_type': 'bookscore', 'total_chunks': 1}

=== TIMING SUMMARY ===
                                      calls     total       avg       min       max
function
pipeline_A                                1  2.488402  2.488402  2.488402  2.488402
pipeline_B                                1  8.543925  8.543925  8.543925  8.543925
pipeline_C                                1  6.119908  6.119908  6.119908  6.119908
pipeline_D                                1  1.548236  1.548236  1.548236  1.548236
task_01_convert_epub                      1  2.346178  2.346178  2.346178  2.346178
task_02_parse_chapters                    1  0.033752  0.033752  0.033752  0.033752
task_03_chunk_story                       1  0.018705  0.018705  0.018705  0.018705
task_11_send_chunk                        1  0.031454  0.031454  0.031454  0.031454
task_12_relation_extraction[textacy]      1  1.555763  1.555763  1.555763  1.555763
task_14_validate_llm[openai]              1  5.135676  5.135676  5.135676  5.135676
task_16_moderate_triples_llm[drop]        1  1.619771  1.619771  1.619771  1.619771
task_20_send_triples                      1  5.701510  5.701510  5.701510  5.701510
task_22_fetch_subgraph[popular]           1  0.325201  0.325201  0.325201  0.325201
task_23_verbalize_triples[raw]            1  0.000352  0.000352  0.000352  0.000352
task_30_summarize_llm[triples]            1  1.492070  1.492070  1.492070  1.492070
task_31_send_summary                      1  0.001635  0.001635  0.001635  0.001635

Total execution time: 36.963s
[CALLBACK] chunk_id=story-1_book-2_chapter-12_p.20963, task=bookscore, status=started
172.18.0.3 - - [10/Dec/2025 04:38:57] "POST /callback HTTP/1.1" 200 -
[DUMP] Saved time records to './logs/elapsed_time.csv'
[CHART] Saved chart 'Average Function Runtime Across Runs' to ./logs/charts/avg_runtime.png
Initial processing complete. Server listening for additional requests from Blazor...
Press Ctrl+C to stop.
[CALLBACK] chunk_id=story-1_book-2_chapter-12_p.20963, task=bookscore, status=completed
[TIME] worker_metric_bookscore took 8.541s
[STORY COMPLETE] All chunks completed metric_bookscore for story 1

=== TIMING SUMMARY ===
                                      calls     total       avg       min       max
function
pipeline_A                                1  2.488402  2.488402  2.488402  2.488402
pipeline_B                                1  8.543925  8.543925  8.543925  8.543925
pipeline_C                                1  6.119908  6.119908  6.119908  6.119908
pipeline_D                                1  1.548236  1.548236  1.548236  1.548236
task_01_convert_epub                      1  2.346178  2.346178  2.346178  2.346178
task_02_parse_chapters                    1  0.033752  0.033752  0.033752  0.033752
task_03_chunk_story                       1  0.018705  0.018705  0.018705  0.018705
task_11_send_chunk                        1  0.031454  0.031454  0.031454  0.031454
task_12_relation_extraction[textacy]      1  1.555763  1.555763  1.555763  1.555763
task_14_validate_llm[openai]              1  5.135676  5.135676  5.135676  5.135676
task_16_moderate_triples_llm[drop]        1  1.619771  1.619771  1.619771  1.619771
task_20_send_triples                      1  5.701510  5.701510  5.701510  5.701510
task_22_fetch_subgraph[popular]           1  0.325201  0.325201  0.325201  0.325201
task_23_verbalize_triples[raw]            1  0.000352  0.000352  0.000352  0.000352
task_30_summarize_llm[triples]            1  1.492070  1.492070  1.492070  1.492070
task_31_send_summary                      1  0.001635  0.001635  0.001635  0.001635
worker_metric_bookscore                   1  8.540844  8.540844  8.540844  8.540844

Total execution time: 45.503s
[DUMP] Saved time records to './logs/elapsed_time.csv'
[CHART] Saved chart 'Average Function Runtime Across Runs' to ./logs/charts/avg_runtime.png
172.18.0.3 - - [10/Dec/2025 04:39:06] "POST /callback HTTP/1.1" 200 -
[CALLBACK] chunk_id=story-1_book-2_chapter-12_p.20963, task=questeval, status=completed
[TIME] worker_metric_questeval took 155.036s
[STORY COMPLETE] All chunks completed metric_questeval for story 1

=== TIMING SUMMARY ===
                                      calls       total         avg         min         max
function
pipeline_A                                1    2.488402    2.488402    2.488402    2.488402
pipeline_B                                1    8.543925    8.543925    8.543925    8.543925
pipeline_C                                1    6.119908    6.119908    6.119908    6.119908
pipeline_D                                1    1.548236    1.548236    1.548236    1.548236
task_01_convert_epub                      1    2.346178    2.346178    2.346178    2.346178
task_02_parse_chapters                    1    0.033752    0.033752    0.033752    0.033752
task_03_chunk_story                       1    0.018705    0.018705    0.018705    0.018705
task_11_send_chunk                        1    0.031454    0.031454    0.031454    0.031454
task_12_relation_extraction[textacy]      1    1.555763    1.555763    1.555763    1.555763
task_14_validate_llm[openai]              1    5.135676    5.135676    5.135676    5.135676
task_16_moderate_triples_llm[drop]        1    1.619771    1.619771    1.619771    1.619771
task_20_send_triples                      1    5.701510    5.701510    5.701510    5.701510
task_22_fetch_subgraph[popular]           1    0.325201    0.325201    0.325201    0.325201
task_23_verbalize_triples[raw]            1    0.000352    0.000352    0.000352    0.000352
task_30_summarize_llm[triples]            1    1.492070    1.492070    1.492070    1.492070
task_31_send_summary                      1    0.001635    0.001635    0.001635    0.001635
worker_metric_bookscore                   1    8.540844    8.540844    8.540844    8.540844
worker_metric_questeval                   1  155.035775  155.035775  155.035775  155.035775

Total execution time: 200.539s
[DUMP] Saved time records to './logs/elapsed_time.csv'
[CHART] Saved chart 'Average Function Runtime Across Runs' to ./logs/charts/avg_runtime.png
[TIME] task_45_eval_coverage took 0.966s
[TIME] task_45_eval_rouge took 2.314s
Downloading builder script: 7.95kB [00:00, 21.9MB/s]
[TIME] task_45_eval_bertscore took 14.956s
[TIME] task_45_eval_ngrams took 0.022s
[TIME] task_45_eval_jsd took 0.008s
[TIME] task_45_eval_ncd took 0.000s
[TIME] task_45_eval_salience took 0.012s
[TIME] task_45_eval_faithfulness took 20.731s
[TIME] task_45_eval_readability took 1.988s
[TIME] task_45_eval_sentence_coherence took 4.693s
[TIME] task_45_eval_entity_grid took 0.529s
[TIME] task_45_eval_diversity took 0.000s
[TIME] task_45_eval_stopwords took 0.002s
Downloading builder script: 6.14kB [00:00, 2.41MB/s]
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Sending payload to Blazor at http://blazor_service:5055/api/metrics
POST succeeded
{'bookID': '2', 'bookTitle': 'The Phoenix and the Carpet', 'summaryText': 'Foot is on the fence between the speaker and the neighboring house, and the speaker is over a place where they do not yet know what is there.', 'goldSummaryText': 'The latch rattled, and clicked. Then the flap of the letter-box lifted itself—every one saw it by the flickering light of the gas-lamp that shone through the leafless lime-tree by the gate—a golden eye seemed to wink at them through the letter-slit, and a cautious beak whispered—\n‘Are you alone?’\n‘It’s the Phoenix,’ said every one, in a voice so joyous, and so full of relief, as to be a sort of whispered shout.\n‘Hush!’ said the voice from the letter-box slit. ‘Your slaves have gone a-merry-making. The latch of this portal is too stiff for my beak. But at the side—the little window above the shelf whereon your bread lies—it i', 'metrics': {'prF1Metrics': [{'name': 'BERTScore', 'precision': 0.8300580978393555, 'recall': 0.7863964438438416, 'f1Score': 0.8076375722885132}], 'qa': {'qaItems': [{'question': 'UNKNOWN', 'goldAnswer': 'UNKNOWN', 'generatedAnswer': 'UNKNOWN', 'isCorrect': False, 'accuracy': 0}, {'question': 'UNKNOWN', 'goldAnswer': 'UNKNOWN', 'generatedAnswer': 'UNKNOWN', 'isCorrect': False, 'accuracy': 0}], 'averageAccuracy': 0}, 'scalarMetrics': [{'name': 'BooookScore (Chang 2024)', 'value': 1}, {'name': 'QuestEval (Scialom 2021)', 'value': 0.2164948418861662}, {'name': 'ROUGE-1', 'value': 0.10526315789473685}, {'name': 'ROUGE-2', 'value': 0}, {'name': 'ROUGE-L', 'value': 0.10526315789473685}, {'name': 'ROUGE-Lsum', 'value': 0.10526315789473685}]}, 'qaResults': []}
[TIME] task_40_post_payload took 26.765s

Output sent to web app.
[TIME] pipeline_E took 73.003s
[PIPELINE FINALIZED] Story 1 fully processed

=== TIMING SUMMARY ===
                                      calls       total         avg         min         max
function
pipeline_A                                1    2.488402    2.488402    2.488402    2.488402
pipeline_B                                1    8.543925    8.543925    8.543925    8.543925
pipeline_C                                1    6.119908    6.119908    6.119908    6.119908
pipeline_D                                1    1.548236    1.548236    1.548236    1.548236
pipeline_E                                1   73.002855   73.002855   73.002855   73.002855
task_01_convert_epub                      1    2.346178    2.346178    2.346178    2.346178
task_02_parse_chapters                    1    0.033752    0.033752    0.033752    0.033752
task_03_chunk_story                       1    0.018705    0.018705    0.018705    0.018705
task_11_send_chunk                        1    0.031454    0.031454    0.031454    0.031454
task_12_relation_extraction[textacy]      1    1.555763    1.555763    1.555763    1.555763
task_14_validate_llm[openai]              1    5.135676    5.135676    5.135676    5.135676
task_16_moderate_triples_llm[drop]        1    1.619771    1.619771    1.619771    1.619771
task_20_send_triples                      1    5.701510    5.701510    5.701510    5.701510
task_22_fetch_subgraph[popular]           1    0.325201    0.325201    0.325201    0.325201
task_23_verbalize_triples[raw]            1    0.000352    0.000352    0.000352    0.000352
task_30_summarize_llm[triples]            1    1.492070    1.492070    1.492070    1.492070
task_31_send_summary                      1    0.001635    0.001635    0.001635    0.001635
task_40_post_payload                      1   26.764646   26.764646   26.764646   26.764646
task_45_eval_bertscore                    1   14.955559   14.955559   14.955559   14.955559
task_45_eval_coverage                     1    0.966215    0.966215    0.966215    0.966215
task_45_eval_diversity                    1    0.000180    0.000180    0.000180    0.000180
task_45_eval_entity_grid                  1    0.529299    0.529299    0.529299    0.529299
task_45_eval_faithfulness                 1   20.731177   20.731177   20.731177   20.731177
task_45_eval_jsd                          1    0.007638    0.007638    0.007638    0.007638
task_45_eval_ncd                          1    0.000164    0.000164    0.000164    0.000164
task_45_eval_ngrams                       1    0.021562    0.021562    0.021562    0.021562
task_45_eval_readability                  1    1.987591    1.987591    1.987591    1.987591
task_45_eval_rouge                        1    2.314435    2.314435    2.314435    2.314435
task_45_eval_salience                     1    0.012061    0.012061    0.012061    0.012061
task_45_eval_sentence_coherence           1    4.692995    4.692995    4.692995    4.692995
task_45_eval_stopwords                    1    0.001511    0.001511    0.001511    0.001511
worker_metric_bookscore                   1    8.540844    8.540844    8.540844    8.540844
worker_metric_questeval                   1  155.035775  155.035775  155.035775  155.035775

Total execution time: 346.527s
[DUMP] Saved time records to './logs/elapsed_time.csv'
[CHART] Saved chart 'Average Function Runtime Across Runs' to ./logs/charts/avg_runtime.png
[CHART] Saved chart 'Saved summary metrics CSV' to ./logs/metrics/chunk_summary.csv
172.18.0.2 - - [10/Dec/2025 04:42:46] "POST /callback HTTP/1.1" 200 -
INFO:werkzeug:172.18.0.2 - - [10/Dec/2025 04:42:46] "POST /callback HTTP/1.1" 200 -