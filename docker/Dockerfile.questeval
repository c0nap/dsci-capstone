# Use a small python base, include the minor version for reproducibility
FROM python:3.8-slim

# Connect the generated Docker image to this repository
LABEL org.opencontainers.image.source="https://github.com/c0nap/dsci-capstone"

# Enable relative paths - helpful name for container's root folder
WORKDIR /flask

# Make Python stdout/stderr unbuffered so logs show immediately
ENV PYTHONUNBUFFERED=1

# Copy dependency list first to leverage build cache
RUN apt-get update && apt-get install -y --no-install-recommends \
    build-essential make git \
 && pip install --upgrade pip setuptools wheel \
 && rm -rf /var/lib/apt/lists/*

COPY req/questeval.txt .
RUN pip install --no-cache-dir -r questeval.txt




# Workaround for QuestEval 0.2.4 + transformers 4.8.1 offline usage
# Issue: transformers 4.8.1 has malformed HuggingFace API URLs, preventing model downloads
# Solution: Pre-download models via git-lfs and patch QuestEval to use local paths

# Download models using git-lfs
RUN apt-get update && apt-get install -y --no-install-recommends git git-lfs \
 && git lfs install \
 && mkdir -p /root/.cache/transformers/ThomasNLG \
 && cd /root/.cache/transformers/ThomasNLG \
 && git clone https://huggingface.co/ThomasNLG/t5-qa_squad2neg-en \
 && cd t5-qa_squad2neg-en && git lfs pull && cd .. \
 && git clone https://huggingface.co/ThomasNLG/t5-qg_squad1-en \
 && cd t5-qg_squad1-en && git lfs pull && cd .. \
 && git clone https://huggingface.co/ThomasNLG/t5-weighter_cnndm-en \
 && cd t5-weighter_cnndm-en && git lfs pull && cd .. \
 && rm -rf */.git* \
 && apt-get remove -y git git-lfs && apt-get autoremove -y

# Patch QuestEval to use local model paths instead of HuggingFace Hub
RUN python3 << 'EOF'
import questeval, os
filepath = os.path.join(os.path.dirname(questeval.__file__), 'questeval_metric.py')
with open(filepath, 'r') as f:
    content = f.read()

# Replace all HuggingFace Hub references with local paths
for model in ['t5-qa_squad2neg-en', 't5-qg_squad1-en', 't5-weighter_cnndm-en', 
              't5-qa_webnlg_synth-en', 't5-qg_webnlg_synth-en']:
    content = content.replace(
        f"f'{{HF_ORGANIZATION}}/{model}'",
        f"'/root/.cache/transformers/ThomasNLG/{model}'"
    )

with open(filepath, 'w') as f:
    f.write(content)
EOF

# Use the offline version of transformers
ENV TRANSFORMERS_OFFLINE=1




# Copy source code into the container (optional .dockerignore)
COPY src/ src/
COPY components/ components/
COPY Makefile pyproject.toml ./

# Declare build args - whether to include .env or .env.dummy
ARG ENV_FILE

# Create .env file
COPY ${ENV_FILE} .env
# Generate .env.docker with mapped hostnames
RUN make env-docker
RUN mv .env.docker .env

# Supply task as command line flag to set worker behavior
CMD ["python", "-m", "src.flask", "--task", "questeval"]